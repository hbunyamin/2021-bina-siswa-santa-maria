%
% This is a borrowed LaTeX template file from UCBerkeley EECS Department.

%
% To familiarize yourself with this template, the body contains
% some examples of its use.  Look them over.  Then you can
% run LaTeX on this file.  After you have LaTeXed this file then
% you can look over the result either by printing it out with
% dvips or using xdvi. "pdflatex template.tex" should also work.
%
\PassOptionsToPackage{svgnames}{xcolor}
\documentclass[twoside,12pt]{article}
\setlength{\oddsidemargin}{0.25 in}
\setlength{\evensidemargin}{-0.25 in}
\setlength{\topmargin}{-0.6 in}
\setlength{\textwidth}{6.5 in}
\setlength{\textheight}{8.5 in}
\setlength{\headsep}{0.75 in}
\setlength{\parindent}{0 in}
\setlength{\parskip}{0.1 in}

%
% ADD PACKAGES here:
%

\usepackage{amsmath,amsfonts,graphicx}
\usepackage[shortlabels]{enumitem}
\usepackage{amssymb}
\usepackage{cancel}
\usepackage{natbib}
\usepackage{bm}
\usepackage{url}

\usepackage{tcolorbox}
\tcbuselibrary{skins,breakable}
\usetikzlibrary{shadings,shadows}

\newenvironment{myblock}[1]{%
    \tcolorbox[beamer,%
    noparskip,breakable,
    colback=LightBlue,colframe=DarkBlue,%
    colbacklower=DarkBlue!75!LightBlue,%
    title=#1]}%
    {\endtcolorbox}
%\usepackage{minted}
\usepackage{lipsum}

% ======================
%  Put Code into a Box
% ======================
%\usepackage{minted}
%\usepackage{tcolorbox}
%\usepackage{etoolbox}
%\BeforeBeginEnvironment{minted}{\begin{tcolorbox}}%
%\AfterEndEnvironment{minted}{\end{tcolorbox}}%

\hyphenation{Bu-nya-min}

\usepackage{csquotes}
%
% The following commands set up the lecnum (lecture number)
% counter and make various numbering schemes work relative
% to the lecture number.
%
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum-\arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}

%
% The following macro is used to generate the header.
%
\newcommand{\lecture}[4]{
   \pagestyle{myheadings}
   \thispagestyle{plain}
   \newpage
   \setcounter{lecnum}{#1}
   \setcounter{page}{1}
   \noindent
   \begin{center}
   \framebox{
      \vbox{\vspace{2mm}
    \hbox to 6.28in { {\bf Persiapan KSN 2021
	\hfill Genap 2020/2021} }
       \vspace{4mm}
       \hbox to 6.28in { {\Large \hfill Lecture #1: #2  \hfill} }
       \vspace{2mm}
%       \hbox to 6.28in { {\it Lecturer: #3 \hfill Scriber: #4} }
		\hbox to 6.28in { {\it \hfill Lecturer: #3 \hfill } } % without scriber
      \vspace{2mm}}
   }
   \end{center}
   \markboth{Lecture #1: #2}{Lecture #1: #2}


\renewcommand\refname{Daftar Pustaka}   

%   {\bf Disclaimer}: {\it These notes may contain factual and/or typographic errors.}
%   \vspace*{4mm}
}

% Convention for citations is authors' initials followed by the year.
% For example, to cite a paper by Leighton and Maggs you would type
% \cite{LM89}, and to cite a paper by Strassen you would type \cite{S69}.
% (To avoid bibliography problems, for now we redefine the \cite command.)
% Also commands that create a suitable format for the reference list.
\renewcommand{\cite}[1]{[#1]}
\def\beginrefs{\begin{list}%
        {[\arabic{equation}]}{\usecounter{equation}
         \setlength{\leftmargin}{2.0truecm}\setlength{\labelsep}{0.4truecm}%
         \setlength{\labelwidth}{1.6truecm}}}
\def\endrefs{\end{list}}
\def\bibentry#1{\item[\hbox{[#1]}]}

%Use this command for a figure; it puts a figure in wherever you want it.
%usage: \fig{NUMBER}{SPACE-IN-INCHES}{CAPTION}
\newcommand{\fig}[3]{
			\vspace{#2}
			\begin{center}
			Figure \thelecnum.#1:~#3
			\end{center}
	}
% Use these for theorems, lemmas, proofs, etc.
\newtheorem{theorem}{Theorem}%[lecnum]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newenvironment{proof}{{\bf Proof:}}{\hfill\rule{2mm}{2mm}}

% **** IF YOU WANT TO DEFINE ADDITIONAL MACROS FOR YOURSELF, PUT THEM HERE:

\newcommand\E{\mathbb{E}}

\begin{document}
%FILL IN THE RIGHT INFO.
%\lecture{**LECTURE-NUMBER**}{**DATE**}{**LECTURER**}{**SCRIBE**}
\lecture{4}{\textit{Analisis \& Logika dari KSNP 2020}}{Hendra Bunyamin}
% **** YOUR NOTES GO HERE:

% Some general latex examples and examples making use of the
% macros follow.  

%	\begin{enumerate}[-,topsep=0pt, nosep,label=\alph*. ]
%		\item How many ways are there to pick two representatives, so that one is a mathematics major and the other is a computer science major?
%		\item How many ways are there to pick one representative who is either a mathematics major or a computer science major?
%	\end{enumerate}
Notes ini membahas teori-teori dan soal-soal KSNP 2020. Referensi yang dapat digunakan oleh adik-adik adalah~\citet{aji2011pemrograman}. 

\section{Aritmetika Modular}  


\citep{aji2011pemrograman}
Dalam subbab ini kita akan membahas \textbf{model} atau \textbf{hypothesis}, \textbf{cost function} atau \textbf{fungsi biaya}, dan \textbf{gradient descent} dari \textit{regularized logistic regression}~\citep{ng2021week3}.

Perbedaan antara \textit{logistic regression} dengan \textit{regularized logistic regression} terletak pada bentuk \textit{cost function} ($J(\theta)$)dan bentuk \textit{gradient} ($\frac{\partial J}{\partial \theta}$) pada algoritma \textit{gradient descent} yang digunakan.

\textbf{Cost function} atau fungsi biaya dari \textit{regularized logistic regression} adalah sebagai berikut
\begin{equation}
	J(\theta) = \frac{1}{m} \sum_{i=1}^m \left[ -y^{(i)} \log h(x^{(i)}) - (1 - y^{(i)}) \log (1 - h(x^{(i)}))  \right] + \frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2.
	\label{eq:cost-function-regularized}
\end{equation}


\begin{myblock}{Latihan}
Sebagai contoh, diberikan $\theta_0 = 1$, $\theta_1 = 2$, dan $\theta_2 = 3$ sehingga model kita menjadi

\begin{equation}
	h(x_1, x_2) = \frac{1}{1 + e^{-(1 + 2x_1 + 3 x_2)}}  
	\label{eq:model-lr-example}
\end{equation}

dengan dataset $x^{(i)} = (x_1^{(i)}, x_2^{(i)})$ untuk $i = 1,2,3,4$ sebagai berikut 
\begin{equation}
	x^{(1)} = (1,1), \; x^{(2)} = (1,2), \; x^{(3)} = (2,1), \; x^{(4)} = (2,2) 
	\label{eq:dataset-x}
\end{equation} 

dan

\begin{equation}
	y^{(1)} = 1, \; y^{(2)} = 0, \; y^{(3)} = 1, \; y^{(4)} = 0.
	\label{eq:dataset-y}
\end{equation} 

Hitunglah \textit{cost function} atau fungsi biaya dari model \textit{regularized logistic regression} dengan $\lambda = 1$ pada Persamaan~(\ref{eq:cost-function-regularized}). 
\end{myblock}

Algoritma optimasi (\textit{optimization algorithm}) yang digunakan masih tetap \textit{gradient descent} seperti berikut
\begin{align}
	\theta_0 &= \theta_0 - \alpha \times \frac{\partial J}{\partial \theta_0} \nonumber \\
	\theta_1 &= \theta_1 - \alpha \times \frac{\partial J}{\partial \theta_1} + \frac{\lambda}{m}\theta_1 \nonumber \\  
	\theta_2 &= \theta_2 - \alpha \times \frac{\partial J}{\partial \theta_2} + \frac{\lambda}{m}\theta_2 \nonumber \\
	         & \vdots \nonumber  \\
	\theta_n &= \theta_n - \alpha \times \frac{\partial J}{\partial \theta_n} + \frac{\lambda}{m}\theta_n  \label{eq:gradient-descent-iterasinya}
\end{align}
dengan $\frac{\partial J}{\partial \theta_0}$, $\frac{\partial J}{\partial \theta_1}$, $\ldots$, $\frac{\partial J}{\partial \theta_n}$ adalah \textit{gradient}-\textit{gradient} untuk setiap $\theta_i$, $i = 0,1, \ldots, n$. Lebih spesifik,
\begin{align}
	\frac{\partial J}{\partial \theta_0} &= \frac{1}{m} \sum_{i=1}^m (h(x^{(i)}) - y^{(i)} ) \label{eq:gradient-0}  \\
	\frac{\partial J}{\partial \theta_j} &= \frac{1}{m} \sum_{i=1}^m (h(x^{(i)}) - y^{(i)} ) x_j^{(i)} + \frac{\lambda}{m} \theta_j && \text{dengan }j = 1, \ldots, n 	\label{eq:gradient-j}
\end{align}
Oleh karena itu, dengan mensubstitusi Persamaan~(\ref{eq:gradient-0}) dan Persamaan~(\ref{eq:gradient-j}) ke Persamaan~(\ref{eq:gradient-descent-iterasinya}), kita peroleh
\begin{align}
	\theta_0 &= \theta_0 - \alpha \frac{1}{m} \sum_{i=1}^{m}(h(x^{(i)}) - y^{(i)}) \text{ dan } \\
	\theta_j &= \theta_j - \alpha \frac{1}{m} \sum_{i=1}^{m}(h(x^{(i)}) - y^{(i)}) x_j^{(i)} + \frac{\lambda}{m} \theta_j  && \text{untuk }j = 1, 2, \ldots, n.
\end{align}

\begin{myblock}{Latihan}
Dengan menggunakan dataset pada (\ref{eq:dataset-x}) dan (\ref{eq:dataset-y}) dan $\alpha = 0.1$ dan $\theta_0 = \theta_1 = \theta_2 = 0$, hitunglah
 	\begin{enumerate}[-,topsep=0pt, nosep,label=\alph*. ]
		\item $\theta_0$ yang baru,
		\item $\theta_1$ yang baru, dan
		\item $\theta_2$ yang baru.
	\end{enumerate}
\end{myblock}

\section{Softmax Regression}
Untuk mengatasi masalah multi-class classification, \textit{logistic regression} dapat digunakan  Selain menggunakan model 


%\begin{lemma}
%This is the first lemma of the lecture.
%\end{lemma}
%
%\begin{proof}
%The proof is by induction on $\ldots$.
%For fun, we throw in a figure.
%%%%NOTE USAGE !
%\fig{1}{1in}{A Fun Figure}
%
%This is the end of the proof, which is marked with a little box.
%\end{proof}
%
%\subsection{A few items of note}
%
%Here is an itemized list:
%\begin{itemize}
%\item this is the first item;
%\item this is the second item.
%\end{itemize}
%
%Here is an enumerated list:
%\begin{enumerate}
%\item this is the first item;
%\item this is the second item.
%\end{enumerate}
%
%Here is an exercise:
%
%{\bf Exercise:}  Show that ${\rm P}\ne{\rm NP}$.
%
%Here is how to define things in the proper mathematical style.
%Let $f_k$ be the $AND-OR$ function, defined by
%
%\[ f_k(x_1, x_2, \ldots, x_{2^k}) = \left\{ \begin{array}{ll}
%
%	x_1 & \mbox{if $k = 0$;} \\
%
%	AND(f_{k-1}(x_1, \ldots, x_{2^{k-1}}),
%	   f_{k-1}(x_{2^{k-1} + 1}, \ldots, x_{2^k}))
%	 & \mbox{if $k$ is even;} \\
%
%	OR(f_{k-1}(x_1, \ldots, x_{2^{k-1}}),
%	   f_{k-1}(x_{2^{k-1} + 1}, \ldots, x_{2^k}))	
%	& \mbox{otherwise.} 
%	\end{array}
%	\right. \]
%
%\begin{theorem}
%This is the first theorem.
%\end{theorem}
%
%\begin{proof}
%This is the proof of the first theorem. We show how to write pseudo-code now.
%%*** USE PSEUDO-CODE ONLY IF IT IS CLEARER THAN AN ENGLISH DESCRIPTION
%
%Consider a comparison between $x$ and~$y$:
%\begin{tabbing}
%\hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \= \hspace*{.25in} \=\kill
%\>{\bf if} $x$ or $y$ or both are in $S$ {\bf then } \\
%\>\> answer accordingly \\
%\>{\bf else} \\
%\>\>    Make the element with the larger score (say $x$) win the comparison \\
%\>\> {\bf if} $F(x) + F(y) < \frac{n}{t-1}$ {\bf then} \\
%\>\>\> $F(x) \leftarrow F(x) + F(y)$ \\
%\>\>\> $F(y) \leftarrow 0$ \\
%\>\> {\bf else}  \\
%\>\>\> $S \leftarrow S \cup \{ x \} $ \\
%\>\>\> $r \leftarrow r+1$ \\
%\>\> {\bf endif} \\
%\>{\bf endif} 
%\end{tabbing}
%
%This concludes the proof.
%\end{proof}
%
%
%\section{Next topic}
%
%Here is a citation, just for fun~\cite{CW87}.


%\section*{References}
%\beginrefs
%\bibentry{CW87}{\sc D.~Coppersmith} and {\sc S.~Winograd}, 
%``Matrix multiplication via arithmetic progressions,''
%{\it Proceedings of the 19th ACM Symposium on Theory of Computing},
%1987, pp.~1--6.
%\endrefs

\bibliographystyle{apalike}
\bibliography{references}

% **** THIS ENDS THE EXAMPLES. 

\end{document}





